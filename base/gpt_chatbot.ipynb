{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d7a377-8911-45f0-8cd0-ef4b34ffc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "default_key = \"\"\"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\"\"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = default_key\n",
    "\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\",default_key)\n",
    "COMPLETION_MODEL = \"text-davinci-003\"\n",
    "\n",
    "prompt = '请你用朋友的语气回复给到客户，并称他为“亲”，他的订单已经发货在路上了，预计在3天之内会送达，订单号2021AEDG，我们很抱歉因为天气的原因物流时间比原来长，感谢他选购我们的商品。'\n",
    "\n",
    "def get_response(prompt, temperature = 1.0):\n",
    "    completions = openai.Completion.create (\n",
    "        engine=COMPLETION_MODEL,\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    message = completions.choices[0].text\n",
    "    return message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "925bec3b-3612-4f24-987c-76d6a733ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "亲，你的订单2021AEDG已经处理，并已经发货在路上，预计在3天之内可以送达。由于天气原因，物流时间可能比原来预期的有点延长，为此我们深表歉意。还是感谢你选购了我们的商品！\n",
      "\n",
      "\n",
      "亲，您的订单2021AEDG已经发货，预计在3天之内会收到，由于天气的影响，导致了物流时间比原来要长，我们感到非常抱歉。感谢您对我们商品的信赖。\n"
     ]
    }
   ],
   "source": [
    "print(get_response(prompt))\n",
    "print(get_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7535a009-38f2-4602-b9b0-b037ecf218d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "亲，您的订单2021AEDG已经发货，预计在3天之内会送达，由于天气原因，物流时间比原来长，我们深表歉意。感谢您选购我们的商品，祝您购物愉快！\n",
      "\n",
      "\n",
      "亲，您的订单2021AEDG已经发货，预计在3天之内会送达。很抱歉因为天气的原因物流时间比原来长，感谢您选购我们的商品，祝您购物愉快！\n"
     ]
    }
   ],
   "source": [
    "print(get_response(prompt,temperature=0.0))\n",
    "print(get_response(prompt,temperature=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637b1df4-a9c4-42f0-9256-7afd247aaca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.准备好肉丝：准备500克肉丝，加入少许盐、生粉和生抽腌制10分钟。\n",
      "2.准备鱼香调料：准备好：2勺素鸡高汤、1勺蚝油、1勺姜蓉、1勺蒜泥、1勺麻油、1勺糖、1勺蒜蓉、1勺番茄酱、1勺料酒、少许香油。\n",
      "3.炒肉丝：热锅放入肉丝，用中火翻炒，加入2勺淀粉，待肉丝变色外酥内嫩后捞出备用。\n",
      "4.炒鱼香调料：热锅注入少许植物油，放入鱼香调料，翻炒至香味出来后加入炒好的肉丝，翻炒煮2-3分钟即可。\n"
     ]
    }
   ],
   "source": [
    "question =  \"\"\"\n",
    "Q : 鱼香肉丝怎么做？\n",
    "A : \n",
    "\"\"\"\n",
    "print(get_response(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e6429a9-5ff8-4d57-a8d5-393f58c741e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，我是一个聊天机器人，请你提出你的问题吧?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  谁是阿斗\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿斗是宋朝的政治家、文学家苏东坡的绰号。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  阿斗不是刘备的儿子吗\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不是，阿斗是苏东坡的绰号，刘备的儿子是刘禅、刘琦和刘翔。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  阿斗和马吵起来了是什么意思\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《阿斗与马吵起来》是苏东坡的一首诗，意思是把政治纠纷比作阿斗和马吵架，想要让它们和解。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  b ye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不用谢！\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  b ye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不用谢！\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def ask_gpt3(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].text.strip()\n",
    "    return message\n",
    "\n",
    "print(\"你好，我是一个聊天机器人，请你提出你的问题吧?\")\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "def generate_prompt(prompt, questions, answers):\n",
    "    num = len(answers)\n",
    "    for i in range(num):\n",
    "        prompt += \"\\n Q : \" + questions[i]\n",
    "        prompt += \"\\n A : \" + answers[i]\n",
    "    prompt += \"\\n Q : \" + questions[num] + \"\\n A : \"        \n",
    "    return prompt\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "    questions.append(user_input)\n",
    "    if user_input.lower() in [\"bye\", \"goodbye\", \"exit\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    prompt = generate_prompt(\"\", questions, answers)\n",
    "\n",
    "    answer = ask_gpt3(prompt)\n",
    "    print(answer)\n",
    "    answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0e675a-66df-4739-9133-d9afcb552790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 你是谁？\n",
      "Unrecognized request argument supplied: messages\n",
      "Assistant : Unrecognized request argument supplied: messages\n",
      "\n",
      "User : 请问鱼香肉丝怎么做？\n",
      "Unrecognized request argument supplied: messages\n",
      "Assistant : Unrecognized request argument supplied: messages\n",
      "\n",
      "User : 那蚝油牛肉呢？\n",
      "Unrecognized request argument supplied: messages\n",
      "Assistant : Unrecognized request argument supplied: messages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Conversation2:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append( {\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        num_of_tokens = response['usage']['total_tokens']\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "        \n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3]\n",
    "        return message, num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8fbace-d984-46dc-97ee-cfda118c3856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/s6yr3rw94mq61mdhqtvyqtc80000gn/T/ipykernel_14169/2735607341.py:20: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'openai' has no attribute 'ChatCompletion'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/lei/miniconda3/envs/gptl/lib/python3.10/site-packages/gradio/routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/lei/miniconda3/envs/gptl/lib/python3.10/site-packages/gradio/blocks.py\", line 1395, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"/Users/lei/miniconda3/envs/gptl/lib/python3.10/site-packages/gradio/blocks.py\", line 1329, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"/Users/lei/miniconda3/envs/gptl/lib/python3.10/site-packages/gradio/components/chatbot.py\", line 235, in postprocess\n",
      "    self._postprocess_chat_messages(message_pair[1]),\n",
      "  File \"/Users/lei/miniconda3/envs/gptl/lib/python3.10/site-packages/gradio/components/chatbot.py\", line 210, in _postprocess_chat_messages\n",
      "    raise ValueError(f\"Invalid message for Chatbot component: {chat_message}\")\n",
      "ValueError: Invalid message for Chatbot component: module 'openai' has no attribute 'ChatCompletion'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "\n",
    "conv = Conversation(prompt, 10)\n",
    "\n",
    "def answer(question, history=[]):\n",
    "    history.append(question)\n",
    "    response = conv.ask(question)\n",
    "    history.append(response)\n",
    "    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n",
    "    return responses, history\n",
    "\n",
    "with gr.Blocks(css=\"#chatbot{height:300px} .overflow-y-auto{height:500px}\") as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "\n",
    "    txt.submit(answer, [txt, state], [chatbot, state])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c1650-73c8-4a2e-b85c-d92a90b1c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
